{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a347603-e611-4882-b8da-6e6fd634003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from model import *\n",
    "conversation = get_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989b61b-c2d9-492a-85f8-6c14a07241b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extracter(text):\n",
    "    input_match = re.search(r'input:\\s*(.*?)\\n', text, re.IGNORECASE | re.DOTALL)\n",
    "    output_match = re.search(r'output:\\s*(.*?)\\n', text, re.IGNORECASE | re.DOTALL)\n",
    "    instruction_match = re.search(r'instruction:\\s*(.*)', text, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    # Bölümleri çıkarıyoruz\n",
    "    input_text = input_match.group(1).strip() if input_match else None\n",
    "    output_text = output_match.group(1).strip() if output_match else None\n",
    "    instruction_text = instruction_match.group(1).strip() if instruction_match else None\n",
    "    \n",
    "    return input_text, output_text, instruction_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f344c8b-b5a0-463b-bd59-6248e061d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def parquet_to_json(parquet_file, json_file):\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    json_str = df.to_json(orient='records', lines=False)\n",
    "    with open(json_file, 'w') as f:\n",
    "        f.write(json_str)\n",
    "\n",
    "    \n",
    "def json_lang_convert(original_file_path):\n",
    "\n",
    "    # Öncü json dosyası oluşturma işlemi\n",
    "    with open(original_file_path, 'r') as file:\n",
    "        original = json.load(file)\n",
    "    \n",
    "    features = original[0]\n",
    "    \n",
    "    with open('TR.json', 'w') as file:\n",
    "        json.dump({'0': features}, file, indent=4)\n",
    "\n",
    "    # Türkçe dönüşüm döngüsü:\n",
    "    with open('TR.json', 'r') as file:\n",
    "        new_json = json.load(file)\n",
    "\n",
    "    hata_kaydedicisi = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            for i in range(hata_kaydedicisi, len(original)+1):\n",
    "                hata_kaydedicisi = i\n",
    "                \n",
    "                last_index = str(len(new_json))\n",
    "                #new_key = str(i)\n",
    "        \n",
    "                entry = original[i]\n",
    "                combined_text = f\"Input: {entry['input']}\\nOutput: {entry['output']}\\nInstruction: {entry['instruction']}\"\n",
    "                \n",
    "                response = conversation.predict(human_input= combined_text)\n",
    "                \n",
    "                input, output, instruction = extracter(response)\n",
    "                \n",
    "                if not (input and output and instruction):\n",
    "                    print(f\" En az bir output boş geldi->\")\n",
    "                    print(\"Tekrar deneniyor...\")\n",
    "                    print(\"input:\",input,\"\\nOutput:\",output,\"\\ninstruction\",instruction)\n",
    "                    print(i/0)\n",
    "                    \n",
    "                new_element = {\n",
    "                    \"input\": input,\n",
    "                    \"output\": output,\n",
    "                    \"instruction\": instruction\n",
    "                }\n",
    "                \n",
    "                new_json[last_index] = new_element\n",
    "                \n",
    "                with open('TR.json', 'w') as file:\n",
    "                    json.dump(new_json, file, indent=4)\n",
    "                    \n",
    "                if i % 100 == 0:\n",
    "                    print(i,\". satır da yazıldı\")\n",
    "            break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Komutan logar.. Bir hata yaklaşıyor şu sayfada -> {hata_kaydedicisi}: {e}\")\n",
    "            print(\"Tekrar deneniyor...\")\n",
    "                \n",
    "\n",
    "file_path = 'train-00000-of-00001-ab79bf9300210e98.parquet'\n",
    "\n",
    "if file_path.split('.')[-1] == 'parquet':\n",
    "    parquet_to_json(file_path, \"temp_parquet.json\")\n",
    "    json_lang_convert(\"./temp_parquet.json\")\n",
    "\n",
    "if file_path.split('.')[-1] == 'json':\n",
    "    json_lang_convert(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a78ed01-cc18-446c-90d6-aad59d778dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7bd3a-e54a-4b87-a630-526cfd344a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527060d9-c0f7-412c-abe4-bb8cd4cf0174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9223bd-47ed-4c89-9c47-024da8c4f77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da873bc1-199b-4ac9-bdda-e83648ce606f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0398a5-03b8-4ff6-b820-f2d1eb3f6b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9bfa4-624f-4e9d-8d6b-c341acc3a9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b681c-a070-4cf3-85ce-84626e2518ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8ef3d-d56c-4702-96f8-d7a7eb108ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "okan",
   "language": "python",
   "name": "okan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
